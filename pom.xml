<?xml version="1.0" encoding="UTF-8"?>
<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at
  http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<project xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"
		 xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">

	<parent>
		<groupId>org.apache</groupId>
		<artifactId>apache</artifactId>
		<version>20</version>
	</parent>

	<modelVersion>4.0.0</modelVersion>

	<groupId>com.exness</groupId>
	<artifactId>flink-exness-jdbc-driver</artifactId>
	<version>${revision}</version>

	<name>Flink Exness JDBC Driver</name>
	<packaging>pom</packaging>

	<repositories>
		<repository>
			<id>repository.jboss.org</id>
			<url>https://repository.jboss.org/nexus/content/groups/public/</url>
			<snapshots>
				<enabled>false</enabled>
			</snapshots>
			<releases>
				<enabled>false</enabled>
			</releases>
		</repository>
	</repositories>

	<modules>
		<module>flink-sql-jdbc-driver</module>
		<module>flink-sql-jdbc-driver-bundle</module>
	</modules>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
		<flink.hadoop.version>2.10.2</flink.hadoop.version>
		<flink.XmxMax>3072m</flink.XmxMax>
		<!-- XmxMax / forkCountITCase -->
		<flink.XmxITCase>1536m</flink.XmxITCase>
		<!-- XmxMax / forkCountUnitTest -->
		<flink.XmxUnitTest>768m</flink.XmxUnitTest>
		<!-- Need to use a user property here because the surefire
			 forkCount is not exposed as a property. With this we can set
			 it on the "mvn" commandline in travis. -->
		<!-- Number of forkCounts for ITCase and UnitTest should take into account allocated memory
			 to the jvm (-Xmx) and the available memory on the machine running the test -->
		<flink.forkCountITCase>2</flink.forkCountITCase>
		<flink.forkCountUnitTest>4</flink.forkCountUnitTest>
		<flink.reuseForks>true</flink.reuseForks>
		<flink.surefire.baseArgLine>-XX:+UseG1GC -Xms256m -XX:+IgnoreUnrecognizedVMOptions ${surefire.module.config}</flink.surefire.baseArgLine>
		<flink.shaded.version>17.0</flink.shaded.version>
		<flink.shaded.jackson.version>2.14.2</flink.shaded.jackson.version>
		<flink.markBundledAsOptional>true</flink.markBundledAsOptional>
		<target.java.version>1.8</target.java.version>
		<slf4j.version>1.7.36</slf4j.version>
		<log4j.version>2.17.1</log4j.version>
		<!-- Overwrite default values from parent pom.
			 IntelliJ IDEA is (sometimes?) using those values to choose target language level
			 and thus is changing back to java 1.6 on each maven re-import -->
		<maven.compiler.source>${target.java.version}</maven.compiler.source>
		<maven.compiler.target>${target.java.version}</maven.compiler.target>
		<scala.macros.version>2.1.1</scala.macros.version>
		<!-- Default scala versions, must be overwritten by build profiles, so we set something
		invalid here -->
		<scala.version>2.12.7</scala.version>
		<scala.binary.version>2.12</scala.binary.version>
		<chill.version>0.7.6</chill.version>
		<!-- keep FlinkTestcontainersConfigurator.configureZookeeperContainer in sync -->
		<zookeeper.version>3.7.1</zookeeper.version>
		<!-- Project `flink-benchmarks` uses zk testing server in `curator-test` for performance
		benchmark, please confirm it will not affect the benchmarks when the version is bumped. -->
		<curator.version>5.4.0</curator.version>
		<avro.version>1.11.4</avro.version>
		<!-- Version for transitive Jackson dependencies that are not used within Flink itself.-->
		<jackson-bom.version>2.15.3</jackson-bom.version>
		<javax.activation.api.version>1.2.0</javax.activation.api.version>
		<jaxb.api.version>2.3.1</jaxb.api.version>
		<junit4.version>4.13.2</junit4.version>
		<junit5.version>5.10.1</junit5.version>
		<archunit.version>1.2.0</archunit.version>
		<mockito.version>3.4.6</mockito.version>
		<powermock.version>2.0.9</powermock.version>
		<hamcrest.version>1.3</hamcrest.version>
		<assertj.version>3.23.1</assertj.version>
		<py4j.version>0.10.9.7</py4j.version>
		<beam.version>2.43.0</beam.version>
		<protoc.version>3.21.7</protoc.version>
		<okhttp.version>3.14.9</okhttp.version>
		<testcontainers.version>1.19.1</testcontainers.version>
		<lz4.version>1.8.0</lz4.version>
		<commons.io.version>2.15.1</commons.io.version>
		<japicmp.skip>false</japicmp.skip>
		<flink.convergence.phase>validate</flink.convergence.phase>
		<!--
			Keeping the MiniKDC version fixed instead of taking hadoop version dependency
			to support testing Kafka, ZK etc., modules that does not have Hadoop dependency
			Starting Hadoop 3, org.apache.kerby will be used instead of MiniKDC. We may have
			to revisit the impact at that time.
		-->
		<minikdc.version>3.2.4</minikdc.version>
		<hive.version>2.3.10</hive.version>
		<orc.version>1.5.6</orc.version>
		<japicmp.referenceVersion>1.19.0</japicmp.referenceVersion>
		<japicmp.outputDir>tools/japicmp-output</japicmp.outputDir>
		<checkstyle.version>9.3</checkstyle.version>
		<!-- can be removed with maven-spotless-plugin:2.38+ -->
		<spotless.skip>false</spotless.skip>
		<spotless.version>2.27.1</spotless.version>
		<spotless.scalafmt.version>3.4.3</spotless.scalafmt.version>
		<spotless.delimiter>package</spotless.delimiter>
		<spotless.license.header>
			/*
			* Licensed to the Apache Software Foundation (ASF) under one
			* or more contributor license agreements.  See the NOTICE file
			* distributed with this work for additional information
			* regarding copyright ownership.  The ASF licenses this file
			* to you under the Apache License, Version 2.0 (the
			* "License"); you may not use this file except in compliance
			* with the License.  You may obtain a copy of the License at
			*
			*     http://www.apache.org/licenses/LICENSE-2.0
			*
			* Unless required by applicable law or agreed to in writing, software
			* distributed under the License is distributed on an "AS IS" BASIS,
			* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
			* See the License for the specific language governing permissions and
			* limitations under the License.
			*/
		</spotless.license.header>

		<!-- This property should contain the add-opens/add-exports commands required for the tests
		     in the given module to pass.
		     It MUST be a space-separated list not containing any newlines,
		     of entries in the form '[-]{2}add-[opens|exports]=<module>/<package>=ALL-UNNAMED'.-->
		<surefire.module.config/>

		<surefire.excludedGroups.github-actions/>
		<surefire.excludedGroups.adaptive-scheduler/>
		<surefire.excludedGroups.jdk/>

		<!-- Can be set to any value to reproduce a specific build. -->
		<test.randomization.seed/>
		<test.unit.pattern>**/*Test.*</test.unit.pattern>
	</properties>

	<dependencies>

		<dependency>
			<groupId>org.apache.flink</groupId>
			<artifactId>flink-shaded-force-shading</artifactId>
			<optional>${flink.markBundledAsOptional}</optional>
		</dependency>

		<!-- Root dependencies for all projects -->

		<!-- Logging API -->
		<dependency>
			<groupId>org.slf4j</groupId>
			<artifactId>slf4j-api</artifactId>
		</dependency>

		<!-- 'javax.annotation' classes like '@Nullable' -->
		<dependency>
			<groupId>com.google.code.findbugs</groupId>
			<artifactId>jsr305</artifactId>
		</dependency>

		<!-- test dependencies -->
		<dependency>
			<groupId>org.junit.jupiter</groupId>
			<artifactId>junit-jupiter</artifactId>
			<scope>test</scope>
		</dependency>

		<!-- tests will have log4j as the default logging framework available -->

		<dependency>
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-slf4j-impl</artifactId>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-api</artifactId>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-core</artifactId>
			<scope>test</scope>
		</dependency>

		<dependency>
			<!-- API bridge between log4j 1 and 2 -->
			<groupId>org.apache.logging.log4j</groupId>
			<artifactId>log4j-1.2-api</artifactId>
			<scope>test</scope>
		</dependency>

	</dependencies>

	<!-- this section defines the module versions that are used if nothing else is specified. -->

	<dependencyManagement>
		<!-- WARN:
			DO NOT put 	guava,
						protobuf,
						asm,
						netty
					here. It will overwrite Hadoop's guava dependency (even though we handle it
			separatly in the flink-shaded-hadoop-2 dependency).
		-->
		<dependencies>
			<dependency>
				<groupId>org.apache.flink</groupId>
				<artifactId>flink-shaded-force-shading</artifactId>
				<version>${flink.shaded.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.flink</groupId>
				<artifactId>flink-shaded-asm-9</artifactId>
				<version>9.5-${flink.shaded.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.flink</groupId>
				<artifactId>flink-shaded-guava</artifactId>
				<version>31.1-jre-${flink.shaded.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.flink</groupId>
				<artifactId>flink-shaded-jackson</artifactId>
				<version>${flink.shaded.jackson.version}-${flink.shaded.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.flink</groupId>
				<artifactId>flink-shaded-jackson-module-jsonSchema</artifactId>
				<version>${flink.shaded.jackson.version}-${flink.shaded.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.flink</groupId>
				<artifactId>flink-shaded-netty</artifactId>
				<version>4.1.91.Final-${flink.shaded.version}</version>
			</dependency>

			<!-- This manages the 'javax.annotation' annotations (JSR305) -->
			<dependency>
				<groupId>com.google.code.findbugs</groupId>
				<artifactId>jsr305</artifactId>
				<version>1.3.9</version>
			</dependency>

			<dependency>
				<groupId>org.slf4j</groupId>
				<artifactId>slf4j-api</artifactId>
				<version>${slf4j.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.logging.log4j</groupId>
				<artifactId>log4j-slf4j-impl</artifactId>
				<version>${log4j.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.logging.log4j</groupId>
				<artifactId>log4j-api</artifactId>
				<version>${log4j.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.logging.log4j</groupId>
				<artifactId>log4j-core</artifactId>
				<version>${log4j.version}</version>
			</dependency>

			<dependency>
				<!-- API bridge between log4j 1 and 2 -->
				<groupId>org.apache.logging.log4j</groupId>
				<artifactId>log4j-1.2-api</artifactId>
				<version>${log4j.version}</version>
			</dependency>

			<dependency>
				<groupId>org.apache.commons</groupId>
				<artifactId>commons-lang3</artifactId>
				<version>3.12.0</version>
			</dependency>

			<dependency>
				<groupId>org.apache.commons</groupId>
				<artifactId>commons-text</artifactId>
				<version>1.10.0</version>
			</dependency>

			<dependency>
				<groupId>com.fasterxml.jackson</groupId>
				<artifactId>jackson-bom</artifactId>
				<type>pom</type>
				<scope>import</scope>
				<version>${jackson-bom.version}</version>
			</dependency>

			<!-- For dependency convergence -->
			<dependency>
				<groupId>org.junit</groupId>
				<artifactId>junit-bom</artifactId>
				<version>${junit5.version}</version>
				<type>pom</type>
				<scope>import</scope>
			</dependency>

			<dependency>
				<groupId>junit</groupId>
				<artifactId>junit</artifactId>
				<version>${junit4.version}</version>
			</dependency>

			<dependency>
				<groupId>org.assertj</groupId>
				<artifactId>assertj-core</artifactId>
				<version>${assertj.version}</version>
				<scope>test</scope>
			</dependency>

			<dependency>
				<groupId>org.apache.commons</groupId>
				<artifactId>commons-math3</artifactId>
				<version>3.6.1</version>
			</dependency>

			<dependency>
				<groupId>org.apache.flink</groupId>
				<artifactId>flink-test-utils-junit</artifactId>
				<version>${project.version}</version>
				<scope>test</scope>
			</dependency>

		</dependencies>
	</dependencyManagement>

	<build>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-jar-plugin</artifactId>
				<version>2.4</version><!--$NO-MVN-MAN-VER$-->
				<configuration>
					<archive>
						<!-- Globally exclude maven metadata, because it may accidentally bundle files we don't intend to -->
						<addMavenDescriptor>false</addMavenDescriptor>
						<manifest>
							<addDefaultImplementationEntries>true</addDefaultImplementationEntries>
							<addDefaultSpecificationEntries>true</addDefaultSpecificationEntries>
						</manifest>
					</archive>
				</configuration>
			</plugin>

			<plugin>
				<!-- activate API compatibility checks -->
				<groupId>com.github.siom79.japicmp</groupId>
				<artifactId>japicmp-maven-plugin</artifactId>
			</plugin>

			<plugin>
				<groupId>org.apache.rat</groupId>
				<artifactId>apache-rat-plugin</artifactId>
				<version>0.13</version>
				<inherited>false</inherited>
				<configuration>
					<skip>true</skip>
				</configuration>
				<executions>
					<execution>
						<phase>validate</phase>
						<goals>
							<goal>check</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-checkstyle-plugin</artifactId>
			</plugin>
			<plugin>
				<groupId>com.diffplug.spotless</groupId>
				<artifactId>spotless-maven-plugin</artifactId>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
			</plugin>

			<!--surefire for unit tests and integration tests-->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<version>3.2.2</version>
				<configuration>
					<!-- enables TCP/IP communication between surefire and forked JVM-->
					<forkNode implementation="org.apache.maven.plugin.surefire.extensions.SurefireForkNodeFactory"/>
					<reuseForks>${flink.reuseForks}</reuseForks>
					<trimStackTrace>false</trimStackTrace>
					<systemPropertyVariables combine.children="append">
						<forkNumber>0${surefire.forkNumber}</forkNumber>
						<!-- $$ ensures that surefire resolves this to the current forkNumber,
						 	instead of maven during initialization -->
						<mvn.forkNumber>$${surefire.forkNumber}</mvn.forkNumber>
						<hadoop.version>${flink.hadoop.version}</hadoop.version>
						<checkpointing.randomization>true</checkpointing.randomization>
						<buffer-debloat.randomization>true</buffer-debloat.randomization>
						<user.country>US</user.country>
						<user.language>en</user.language>
						<!-- force the use of the Changelog State Backend in tests on mini-cluster
							on: enable CheckpointingOptions.ENABLE_STATE_CHANGE_LOG on cluster level
							random: enable it randomly, unless explicitly set
							unset: don't alter the configuration
						-->
						<checkpointing.changelog>random</checkpointing.changelog>
						<!-- Expose as property so that test utils that spawn JVMs can pick it up. -->
						<surefire.module.config>${surefire.module.config}</surefire.module.config>
						<project.basedir>${project.basedir}</project.basedir>
						<!--suppress MavenModelInspection -->
						<test.randomization.seed>${test.randomization.seed}</test.randomization.seed>
						<junit.jupiter.extensions.autodetection.enabled>true</junit.jupiter.extensions.autodetection.enabled>
						<!-- Enabled the parallel test execution feature. -->
						<!-- Tests and test classes can be enabled for concurrent execution using @Execution(ExecutionMode.CONCURRENT). -->
						<junit.jupiter.execution.parallel.enabled>true</junit.jupiter.execution.parallel.enabled>
						<!-- Tests are by default executed by a single thread; parallel execution is opt-in. -->
						<junit.jupiter.execution.parallel.mode.default>same_thread</junit.jupiter.execution.parallel.mode.default>
						<!-- Tests suites are by default executed by a single thread; parallel execution is opt-in. -->
						<junit.jupiter.execution.parallel.mode.classes.default>same_thread</junit.jupiter.execution.parallel.mode.classes.default>
						<!-- automatically adjust parallelism based on available cpu/processor cores-->
						<junit.jupiter.execution.parallel.config.strategy>dynamic</junit.jupiter.execution.parallel.config.strategy>
					</systemPropertyVariables>
					<!-- This is picked up by IntelliJ -->
					<argLine>${flink.surefire.baseArgLine}</argLine>
				</configuration>
				<executions>
					<!--execute all the unit tests-->
					<execution>
						<id>default-test</id>
						<phase>test</phase>
						<goals>
							<goal>test</goal>
						</goals>
						<configuration>
							<includes>
								<include>${test.unit.pattern}</include>
							</includes>
							<forkCount>${flink.forkCountUnitTest}</forkCount>
							<argLine>${flink.surefire.baseArgLine} -Xmx${flink.XmxUnitTest}</argLine>
						</configuration>
					</execution>
					<!--execute all the integration tests-->
					<execution>
						<id>integration-tests</id>
						<phase>integration-test</phase>
						<goals>
							<goal>test</goal>
						</goals>
						<configuration>
							<includes>
								<include>**/*.*</include>
							</includes>
							<excludes>
								<exclude>${test.unit.pattern}</exclude>
								<!-- Exclude classes generated by Scala that surefire rejects
								     e.g., 'org.apache.flink.api.scala.typeutils.Foo$Bar$Foobar'. -->
								<exclude>**/*$*</exclude>
							</excludes>
							<forkCount>${flink.forkCountITCase}</forkCount>
							<argLine>${flink.surefire.baseArgLine} -Xmx${flink.XmxITCase}</argLine>
							<reuseForks>false</reuseForks>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-enforcer-plugin</artifactId>
				<executions>
					<execution>
						<id>enforce-maven</id>
						<goals>
							<goal>enforce</goal>
						</goals>
						<configuration>
							<rules>
								<requireMavenVersion>
									<version>[3.8.6,)</version>
								</requireMavenVersion>
								<requireJavaVersion>
									<version>${target.java.version}</version>
								</requireJavaVersion>
							</rules>
						</configuration>
					</execution>
					<execution>
						<id>ban-unsafe-snakeyaml</id>
						<goals>
							<goal>enforce</goal>
						</goals>
						<configuration>
							<rules>
								<bannedDependencies>
									<excludes>
										<exclude>org.yaml:snakeyaml:(,1.31]</exclude>
									</excludes>
									<includes>
										<!-- Snakeyaml is pulled in by many modules without using it in production,
											so there's no benefit in us investing time into bumping these. -->
										<include>org.yaml:snakeyaml:(,1.31]:*:test</include>
									</includes>
									<message>Older snakeyaml versions are not allowed due to security vulnerabilities.</message>
								</bannedDependencies>
							</rules>
						</configuration>
					</execution>
					<execution>
						<id>ban-unsafe-jackson</id>
						<goals>
							<goal>enforce</goal>
						</goals>
						<configuration>
							<rules>
								<bannedDependencies>
									<excludes>
										<exclude>com.fasterxml.jackson*:*:(,2.12.0]</exclude>
									</excludes>
									<message>Older jackson versions are not allowed due to security vulnerabilities.</message>
								</bannedDependencies>
							</rules>
						</configuration>
					</execution>
					<execution>
						<id>forbid-log4j-1</id>
						<goals>
							<goal>enforce</goal>
						</goals>
						<configuration>
							<rules>
								<bannedDependencies>
									<excludes>
										<exclude>log4j:log4j</exclude>
										<exclude>org.slf4j:slf4j-log4j12</exclude>
										<exclude>ch.qos.reload4j:reload4j</exclude>
										<exclude>org.slf4j:slf4j-reload4j</exclude>
									</excludes>
									<message>Log4j 1 and Reload4J dependencies are not allowed because they conflict with Log4j 2. If the dependency absolutely requires the Log4j 1 API, use 'org.apache.logging.log4j:log4j-1.2-api'.</message>
								</bannedDependencies>
							</rules>
						</configuration>
					</execution>
					<execution>
						<id>forbid-direct-akka-rpc-dependencies</id>
						<goals>
							<goal>enforce</goal>
						</goals>
						<configuration>
							<rules>
								<bannedDependencies>
									<excludes>
										<exclude>org.apache.flink:flink-rpc-akka</exclude>
									</excludes>
									<message>
										Direct dependencies on flink-rpc-akka are not allowed. Depend on flink-rpc-akka-loader instead, and use RpcSystem#load or the TestingRpcService.
									</message>
								</bannedDependencies>
							</rules>
						</configuration>
					</execution>
					<execution>
						<id>forbid-direct-table-planner-dependencies</id>
						<goals>
							<goal>enforce</goal>
						</goals>
						<configuration>
							<rules>
								<bannedDependencies>
									<excludes>
										<exclude>org.apache.flink:flink-table-planner_${scala.binary.version}</exclude>
									</excludes>
									<includes>
										<include>org.apache.flink:flink-table-planner_${scala.binary.version}:*:*:test</include>
									</includes>
									<message>
										Direct dependencies on flink-table-planner are not allowed.
										You should depend on either Table API modules or flink-table-planner-loader.
									</message>
								</bannedDependencies>
							</rules>
						</configuration>
					</execution>
					<execution>
						<id>dependency-convergence</id>
						<!-- disabled by default as it interacts badly with shade-plugin -->
						<phase>none</phase>
						<goals>
							<goal>enforce</goal>
						</goals>
						<configuration>
							<rules>
								<dependencyConvergence/>
							</rules>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<configuration>
					<!-- This section contains the core configuration that is applied to every jar that we create.-->
					<filters combine.children="append">
						<filter>
							<artifact>*</artifact>
							<excludes>
								<!-- Globally exclude log4j.properties from our JAR files. -->
								<exclude>log4j.properties</exclude>
								<exclude>log4j2.properties</exclude>
								<exclude>log4j-test.properties</exclude>
								<exclude>log4j2-test.properties</exclude>
								<!-- Do not copy the signatures in the META-INF folder.
								Otherwise, this might cause SecurityExceptions when using the JAR. -->
								<exclude>META-INF/*.SF</exclude>
								<exclude>META-INF/*.DSA</exclude>
								<exclude>META-INF/*.RSA</exclude>
								<!-- META-INF/maven can contain 2 things:
									- For archetypes, it contains an archetype-metadata.xml.
									- For other jars, it contains the pom for all dependencies under the respective <groupId>/<artifactId>/ directory.

								 	We want to exclude the poms because they may be under an incompatible license,
								 	however the archetype metadata is required and we need to keep that around.

								 	This pattern excludes directories under META-INF/maven.
								 	('?*/**' does not work because '**' also matches zero directories;
								 	everything that matches '?*' also matches '?*/**')

									The initial '**' allows the pattern to also work for multi-release jars that may contain such entries under
									'META-INF/versions/11/META-INF/maven/'.
								 	-->
								<exclude>**/META-INF/maven/?*/?*/**</exclude>
							</excludes>
						</filter>
					</filters>
					<transformers combine.children="append">
						<!-- The service transformer is needed to merge META-INF/services files -->
						<transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
						<!-- The ApacheNoticeResourceTransformer collects and aggregates NOTICE files -->
						<transformer implementation="org.apache.maven.plugins.shade.resource.ApacheNoticeResourceTransformer">
							<projectName>Apache Flink</projectName>
							<encoding>UTF-8</encoding>
						</transformer>
					</transformers>
				</configuration>
				<executions>
					<execution>
						<id>shade-flink</id>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
						<configuration>
							<shadeTestJar>false</shadeTestJar>
							<shadedArtifactAttached>false</shadedArtifactAttached>
							<createDependencyReducedPom>true</createDependencyReducedPom>
							<!-- Filters MUST be appended; merging filters does not work properly, see MSHADE-305 -->
							<filters combine.children="append">
								<!-- drop entries into META-INF and NOTICE files for the dummy artifact -->
								<filter>
									<artifact>org.apache.flink:flink-shaded-force-shading</artifact>
									<excludes>
										<exclude>**</exclude>
									</excludes>
								</filter>
								<!-- io.netty:netty brings its own LICENSE.txt which we don't need -->
								<filter>
									<artifact>io.netty:netty</artifact>
									<excludes>
										<exclude>META-INF/LICENSE.txt</exclude>
									</excludes>
								</filter>
							</filters>
							<artifactSet>
								<includes>
									<!-- Unfortunately, the next line is necessary for now to force the execution
									of the Shade plugin upon all sub modules. This will generate effective poms,
									i.e. poms which do not contain properties which are derived from this root pom.
									In particular, the Scala version properties are defined in the root pom and without
									shading, the root pom would have to be Scala suffixed and thereby all other modules.
									-->
									<include>org.apache.flink:flink-shaded-force-shading</include>
								</includes>
							</artifactSet>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<!-- generate configuration docs -->
			<plugin>
				<groupId>org.commonjava.maven.plugins</groupId>
				<artifactId>directory-maven-plugin</artifactId>
				<version>0.1</version>
				<executions>
					<execution>
						<id>directories</id>
						<goals>
							<goal>directory-of</goal>
						</goals>
						<phase>initialize</phase>
						<configuration>
							<property>rootDir</property>
							<project>
								<groupId>org.apache.flink</groupId>
								<artifactId>flink-exness-jdbc-driver</artifactId>
							</project>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<plugin>
				<groupId>org.cyclonedx</groupId>
				<artifactId>cyclonedx-maven-plugin</artifactId>
				<version>2.7.7</version>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>makeBom</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
		</plugins>

		<pluginManagement>
			<plugins>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-compiler-plugin</artifactId>
					<version>3.8.0</version>
					<configuration>
						<source>${target.java.version}</source>
						<target>${target.java.version}</target>
						<!-- The semantics of this option are reversed, see MCOMPILER-209. -->
						<useIncrementalCompilation>false</useIncrementalCompilation>
						<compilerArgs>
							<!-- Prevents recompilation due to missing package-info.class, see MCOMPILER-205 -->
							<arg>-Xpkginfo:always</arg>
						</compilerArgs>
					</configuration>
				</plugin>

				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-clean-plugin</artifactId>
					<version>3.1.0</version>
					<configuration>
						<filesets>
							<fileset>
								<directory>${project.basedir}</directory>
								<includes>
									<include>dependency-reduced-pom.xml</include>
								</includes>
							</fileset>
						</filesets>
					</configuration>
				</plugin>

				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-checkstyle-plugin</artifactId>
					<version>3.3.1</version>
					<dependencies>
						<dependency>
							<groupId>com.puppycrawl.tools</groupId>
							<artifactId>checkstyle</artifactId>
							<!-- Note: match version with docs/flinkDev/ide_setup.md -->
							<version>${checkstyle.version}</version>
						</dependency>
					</dependencies>
					<executions>
						<execution>
							<id>validate</id>
							<phase>validate</phase>
							<goals>
								<goal>check</goal>
							</goals>
						</execution>
					</executions>
					<configuration>
						<skip>true</skip>
					</configuration>
				</plugin>

				<plugin>
					<groupId>com.diffplug.spotless</groupId>
					<artifactId>spotless-maven-plugin</artifactId>
					<version>${spotless.version}</version>
					<configuration>
						<skip>${spotless.skip}</skip>
						<java>
							<googleJavaFormat>
								<version>1.7</version>
								<style>AOSP</style>
							</googleJavaFormat>

							<!-- \# refers to the static imports -->
							<importOrder>
								<order>org.apache.flink,org.apache.flink.shaded,,javax,java,scala,\#</order>
							</importOrder>

							<removeUnusedImports />
						</java>
					</configuration>
					<executions>
						<execution>
							<id>spotless-check</id>
							<phase>validate</phase>
							<goals>
								<goal>check</goal>
							</goals>
						</execution>
					</executions>
				</plugin>


				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-javadoc-plugin</artifactId>
					<version>3.8.0</version>
					<configuration>
						<quiet>true</quiet>
						<detectOfflineLinks>false</detectOfflineLinks>
						<additionalJOptions>
							<additionalJOption>-Xdoclint:none</additionalJOption>
							<additionalJOption>--allow-script-in-comments</additionalJOption>
						</additionalJOptions>
					</configuration>
				</plugin>

				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-enforcer-plugin</artifactId>
					<version>3.1.0</version>
				</plugin>

				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-dependency-plugin</artifactId>
					<version>3.2.0</version>
					<configuration>
						<ignoredUsedUndeclaredDependencies combine.children="append">
							<!-- allow using transitive Flink dependencies for brevity -->
							<dependency>org.apache.flink:*</dependency>
							<!-- False positive since we use hamcrest-all -->
							<dependency>org.hamcrest:hamcrest-core</dependency>
							<!-- transitive powermock test dependencies; excluded for brevity -->
							<dependency>org.powermock:powermock-core</dependency>
							<dependency>org.powermock:powermock-reflect</dependency>
							<dependency>org.powermock:powermock-api-support</dependency>
						</ignoredUsedUndeclaredDependencies>
						<ignoredUnusedDeclaredDependencies combine.children="append">
							<!-- build dependency, required for shading; does not contain any classes -->
							<dependency>org.apache.flink:force-shading</dependency>
							<!-- compile dependencies; defined in root pom for brevity -->
							<dependency>com.google.code.findbugs:jsr305</dependency>
							<dependency>org.scala-lang:scala-compiler</dependency>
							<!-- logging dependencies; defined in root pom for brevity
									some modules may not use any logging, but that's not a problem
									implementations are loaded via reflection and are always detected as unused -->
							<dependency>org.slf4j:slf4j-api</dependency>
							<!-- log4j1 -->
							<dependency>log4j:log4j</dependency>
							<dependency>org.slf4j:slf4j-log4j12</dependency>
							<!-- log4j2 -->
							<dependency>org.apache.logging.log4j:log4j-slf4j-impl</dependency>
							<dependency>org.apache.logging.log4j:log4j-api</dependency>
							<dependency>org.apache.logging.log4j:log4j-core</dependency>
							<dependency>org.apache.logging.log4j:log4j-1.2-api</dependency>
							<!-- test dependencies; defined in root pom for brevity -->
							<dependency>org.apache.flink:flink-test-utils-junit</dependency>
							<dependency>junit:junit</dependency>
							<dependency>org.mockito:mockito-core</dependency>
							<dependency>org.powermock:powermock-api-mockito2</dependency>
							<dependency>org.powermock:powermock-module-junit4</dependency>
							<dependency>org.hamcrest:hamcrest-all</dependency>
						</ignoredUnusedDeclaredDependencies>
					</configuration>
				</plugin>

				<!-- Pin the version of the maven shade plugin -->
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-shade-plugin</artifactId>
					<version>3.5.1</version>
				</plugin>

				<plugin>
					<!-- Inherited from Apache parent, but not actually used. Disable to reduce noise. -->
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-site-plugin</artifactId>
					<executions>
						<execution>
							<id>attach-descriptor</id>
							<phase>none</phase>
						</execution>
					</executions>
				</plugin>

				<!-- set scala maven plugin version -->
				<plugin>
					<groupId>net.alchim31.maven</groupId>
					<artifactId>scala-maven-plugin</artifactId>
					<version>3.2.2</version>
					<configuration>
						<args>
							<arg>-nobootcp</arg>
							<arg>-target:jvm-${target.java.version}</arg>
						</args>
						<jvmArgs>
							<arg>-Xss2m</arg>
						</jvmArgs>
					</configuration>
				</plugin>

				<!-- Configuration for the binary compatibility checker -->
				<plugin>
					<groupId>com.github.siom79.japicmp</groupId>
					<artifactId>japicmp-maven-plugin</artifactId>
					<version>0.17.1</version>
					<configuration>
						<oldVersion>
							<dependency>
								<groupId>org.apache.flink</groupId>
								<artifactId>${project.artifactId}</artifactId>
								<version>${japicmp.referenceVersion}</version>
								<type>${project.packaging}</type>
							</dependency>
						</oldVersion>
						<newVersion>
							<file>
								<path>${project.build.directory}/${project.artifactId}-${project.version}.${project.packaging}</path>
							</file>
						</newVersion>
						<parameter>
							<onlyModified>true</onlyModified>
							<includes>
								<include>@org.apache.flink.annotation.Public</include>
								<!-- The following line is un-commented by tools/releasing/update_japicmp_configuration.sh
								 	as part of the release process -->
								<!--<include>@org.apache.flink.annotation.PublicEvolving</include>-->
							</includes>
							<excludes>
								<exclude>@org.apache.flink.annotation.Experimental</exclude>
								<exclude>@org.apache.flink.annotation.PublicEvolving</exclude>
								<exclude>@org.apache.flink.annotation.Internal</exclude>
								<!-- MARKER: start exclusions; these will be wiped by tools/releasing/update_japicmp_configuration.sh -->
								<exclude>org.apache.flink.api.common.state.AggregatingState</exclude>
								<exclude>org.apache.flink.api.common.state.AppendingState</exclude>
								<exclude>org.apache.flink.api.common.state.BroadcastState</exclude>
								<exclude>org.apache.flink.api.common.state.ListState</exclude>
								<exclude>org.apache.flink.api.common.state.MapState</exclude>
								<exclude>org.apache.flink.api.common.state.MergingState</exclude>
								<exclude>org.apache.flink.api.common.state.ReadOnlyBroadcastState</exclude>
								<exclude>org.apache.flink.api.common.state.ReducingState</exclude>
								<exclude>org.apache.flink.api.common.state.State</exclude>
								<exclude>org.apache.flink.api.common.state.ValueState</exclude>
								<exclude>org.apache.flink.api.common.functions.AggregateFunction</exclude>
								<exclude>org.apache.flink.api.common.functions.ReduceFunction</exclude>
								<exclude>org.apache.flink.api.common.functions.Function</exclude>
								<exclude>org.apache.flink.api.java.functions.KeySelector</exclude>
								<exclude>org.apache.flink.util.function.FunctionWithException</exclude>
								<exclude>org.apache.flink.util.function.LongFunctionWithException</exclude>
								<exclude>org.apache.flink.util.function.RunnableWithException</exclude>
								<exclude>org.apache.flink.util.function.SerializableFunction</exclude>
								<exclude>org.apache.flink.util.function.SupplierWithException</exclude>
								<exclude>org.apache.flink.util.function.ThrowingConsumer</exclude>
								<!-- Disable check for two sink methods. -->
								<!-- TypeSerializer needs to be considered upgraded to Public. Tracked under FLINK-35566 -->
								<exclude>org.apache.flink.api.connector.sink2.WriterInitContext#createInputSerializer()</exclude>
								<!-- SinkV1 is deprecated but relies on an Experimental interface. Keeping this for legacy purposes  -->
								<exclude>org.apache.flink.api.connector.sink2.WriterInitContext#metadataConsumer()</exclude>
								<!-- MARKER: end exclusions -->
							</excludes>
							<accessModifier>public</accessModifier>
							<breakBuildOnModifications>false</breakBuildOnModifications>
							<breakBuildOnBinaryIncompatibleModifications>true</breakBuildOnBinaryIncompatibleModifications>
							<breakBuildOnSourceIncompatibleModifications>true</breakBuildOnSourceIncompatibleModifications>
							<onlyBinaryIncompatible>false</onlyBinaryIncompatible>
							<includeSynthetic>true</includeSynthetic>
							<ignoreMissingClasses>false</ignoreMissingClasses>
							<skipPomModules>true</skipPomModules>
							<!-- Don't break build on newly added maven modules -->
							<ignoreNonResolvableArtifacts>true</ignoreNonResolvableArtifacts>
							<packagingSupporteds>
								<packagingSupported>jar</packagingSupported>
							</packagingSupporteds>
						</parameter>
						<projectBuildDir>${rootDir}/${japicmp.outputDir}/${project.artifactId}</projectBuildDir>
						<dependencies>
							<dependency>
								<groupId>org.apache.flink</groupId>
								<artifactId>flink-annotations</artifactId>
								<version>${project.version}</version>
							</dependency>
						</dependencies>
					</configuration>
					<executions>
						<execution>
							<phase>verify</phase>
							<goals>
								<goal>cmp</goal>
							</goals>
						</execution>
					</executions>
				</plugin>

				<plugin>
					<!-- run via "mvn org.owasp:dependency-check-maven:aggregate" -->
					<groupId>org.owasp</groupId>
					<artifactId>dependency-check-maven</artifactId>
					<version>5.0.0-M2</version>
					<configuration>
						<format>ALL</format>
						<skipSystemScope>true</skipSystemScope>
						<skipProvidedScope>true</skipProvidedScope>
						<excludes>
							<exclude>*flink-docs</exclude>
							<exclude>*flink-end-to-end-tests</exclude>
							<exclude>*flink-fs-tests*</exclude>
							<exclude>*flink-yarn-tests*</exclude>
						</excludes>
					</configuration>
				</plugin>
				<plugin>
					<groupId>org.apache.maven.plugins</groupId>
					<artifactId>maven-deploy-plugin</artifactId>
					<version>2.7</version>
				</plugin>
			</plugins>
		</pluginManagement>
	</build>
<profiles>
  <profile>
    <id>release</id>
    <activation>
      <activeByDefault>true</activeByDefault>
    </activation>
    <build>
      <plugins>
        <!-- GPG Plugin -->
        <plugin>
          <groupId>org.apache.maven.plugins</groupId>
          <artifactId>maven-gpg-plugin</artifactId>
          <version>3.1.0</version>
          <executions>
            <execution>
              <id>sign-artifacts</id>
              <phase>verify</phase>
              <goals>
                <goal>sign</goal>
              </goals>
            </execution>
          </executions>
        </plugin>
        <!-- Sources JAR -->
        <plugin>
          <groupId>org.apache.maven.plugins</groupId>
          <artifactId>maven-source-plugin</artifactId>
          <version>3.2.1</version>
          <executions>
            <execution>
              <id>attach-sources</id>
              <goals>
                <goal>jar</goal>
              </goals>
            </execution>
          </executions>
        </plugin>
        <!-- Javadoc JAR -->
        <plugin>
          <groupId>org.apache.maven.plugins</groupId>
          <artifactId>maven-javadoc-plugin</artifactId>
          <version>3.4.1</version>
          <executions>
            <execution>
              <id>attach-javadocs</id>
              <goals>
                <goal>jar</goal>
              </goals>
            </execution>
          </executions>
        </plugin>
        <!-- Central Publishing Plugin -->
        <plugin>
          <groupId>org.sonatype.central</groupId>
          <artifactId>central-publishing-maven-plugin</artifactId>
          <version>0.8.0</version>
          <extensions>true</extensions>
          <configuration>
            <publishingServerId>central</publishingServerId>
            <autoPublish>true</autoPublish>
            <waitUntil>published</waitUntil>
          </configuration>
        </plugin>
      </plugins>
    </build>
  </profile>
</profiles>
</project>
